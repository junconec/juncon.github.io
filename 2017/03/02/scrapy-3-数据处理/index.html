
<!DOCTYPE html>
<html lang="zh-CN" class="loading">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>scrapy-3-数据处理 - JUNCON个人博客</title>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate">
    <meta name="keywords" content="TriDiamond Obsidian,"> 
    <meta name="description" content="####itemPipeline数据处理
介绍
启动方式
导出数据
一、介绍
在scrapy中，数据经过spider请求解析后，就需要进行对应模型化处理，在scrapy中itemPipeline负责,"> 
    <meta name="author" content="Juncon"> 
    <link rel="alternative" href="atom.xml" title="JUNCON个人博客" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    <link href="https://fonts.loli.net/css?family=Roboto+Mono|Rubik&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_1429596_nzgqgvnmkjb.css">
    <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.7.2/animate.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
    <link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/codemirror.min.css">
    <link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/theme/dracula.css">
    <link rel="stylesheet" href="/css/obsidian.css">
    <link rel="stylesheet" href="/css/ball-atom.min.css">
</head>
</html>

<body class="loading">
    <div class="loader">
        <div class="la-ball-atom la-2x">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
    <span id="config-title" style="display:none">JUNCON个人博客</span>
    <div id="loader"></div>
    <div id="single">
    <div class="scrollbar gradient-bg-rev"></div>
<div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <div class="navigation animated fadeIn fast delay-1s">
        <img id="home-icon" class="icon-home" src="/img/favicon.png" alt="" data-url="http://yoursite.com">
        <div id="play-icon" title="Play/Pause" class="iconfont icon-play"></div>
        <h3 class="subtitle">scrapy-3-数据处理</h3>
        <div class="social">
            <!--        <div class="like-icon">-->
            <!--            <a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
            <!--        </div>-->
            <div>
                <div class="share">
                    
                        <a href="javascript:;" class="iconfont icon-share1"></a>
                        <div class="share-component-cc" data-disabled="facebook,douban,linkedin,diandian,tencent,google"></div>
                    
                </div>
            </div>
        </div>
    </div>
</div>

    <div class="section">
        <div class=article-header-wrapper>
    <div class="article-header">
        <div class="article-cover animated fadeIn" style="
            animation-delay: 600ms;
            animation-duration: 1.2s;
            background-image: 
                radial-gradient(ellipse closest-side, rgba(0, 0, 0, 0.65), #100e17),
                url(/img/cover.jpg) ">
        </div>
        <div class="else">
            <p class="animated fadeInDown">
                
                <a href="/categories/爬虫"><b>「
                    </b>爬虫<b> 」</b></a>
                
                三月 02, 2017
            </p>
            <h3 class="post-title animated fadeInDown"><a href="/2017/03/02/scrapy-3-数据处理/" title="scrapy-3-数据处理">scrapy-3-数据处理</a>
            </h3>
            
            <p class="post-count animated fadeInDown">
                
                <span>
                    <b class="iconfont icon-text2"></b> <i>文章字数</i>
                    12k
                </span>
                
                
                <span>
                    <b class="iconfont icon-timer__s"></b> <i>阅读约需</i>
                    11 mins.
                </span>
                
                
                
                <span id="busuanzi_container_page_pv">
                    <b class="iconfont icon-read"></b> <i>阅读次数</i>
                    <span id="busuanzi_value_page_pv">0</span>
                </span>
                
            </p>
            
            
            <ul class="animated fadeInDown post-tags-list"><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/python/">python</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/scrapy/">scrapy</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/scrapy-3-数据处理/">scrapy-3-数据处理</a></li><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/爬虫/">爬虫</a></li></ul>
            
        </div>
    </div>
</div>

<div class="screen-gradient-after">
    <div class="screen-gradient-content">
        <div class="screen-gradient-content-inside">
            <div class="bold-underline-links screen-gradient-sponsor">
                <p>
                    <span class="animated fadeIn delay-1s"></span>
                </p>
            </div>
        </div>
    </div>
</div>

<div class="article">
    <div class='main'>
        <div class="content markdown animated fadeIn">
            <p>####itemPipeline数据处理</p>
<p>介绍</p>
<p>启动方式</p>
<p>导出数据</p>
<p>一、介绍</p>
<p>在scrapy中，数据经过spider请求解析后，就需要进行对应模型化处理，在scrapy中itemPipeline负责数据处理</p>
<p>   itemPipeline相当于数据处理的过滤器一样，可以配置多个，每一个itemPipline处理完成return后，会进入下一个itemPipeline中，如果不return，则表示放弃这段数据</p>
<p>   每一个itemPipeline中，需要实现process_item(self,item,spider):这个方法，在这个方法中进行处理数据</p>
<p>   open_spider(self,spider) 一般Spider打开时，回调该方法，通常用于处理数据之前的某些初始化工作，比如连接数据库</p>
<p>   close_spider(self,spider)一般Spider关闭时，回调该方法，通常用于处理完成所有数据之后，如关闭数据库</p>
<p>   from_crawler(cls,crawler) 一般没啥用，创建ItemPipeline对象时候回调该类方法</p>
<p>二、启动方式</p>
<p>启动方式有2种方式，一种在setting.py进行配置，一种在爬虫文件中配置</p>
<p>方式1 在setting.py中进行配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES=&#123;<span class="string">'example.pipelines.PriceConverterPipeline'</span>:<span class="number">300</span>&#125;</span><br></pre></td></tr></table></figure>

<p>example是工程名字，pipelines是所在文件夹，PriceConverterPipeline自定义的itemPipeline，300是优先级，数值越小优先度越大</p>
<p>多个ItemPipLine的应用，可以使用去重操作，在自定义的ItemPipLine中init初始化时候，初始一个set集合，在每次响应process_item时候对比name，从set中进行对比即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DuplicatesPipeline</span><span class="params">(object)</span>:</span>   </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span>      </span><br><span class="line">        self.book_set=set()   </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self,item,spider)</span>:</span>      </span><br><span class="line">            name=item[<span class="string">'name'</span>]      </span><br><span class="line">            <span class="keyword">if</span> name <span class="keyword">in</span> self.book_set:      </span><br><span class="line">                <span class="comment">#数据重复不进行返回即可      </span></span><br><span class="line">                self.book_sett.add(name)      </span><br><span class="line">                <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<p>建立完成DuplicatesPipeline后需要在Setting.py中配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES=&#123;<span class="string">'example.pipelines,PriceConverterPipeline'</span>:<span class="number">300</span>,<span class="string">'example.pipelines.TestPipeline'</span>:<span class="number">400</span>,&#125;</span><br></pre></td></tr></table></figure>



<p>方式2 在Spider文件中可以指定</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Class Spider1(scrapy.Spider):     </span><br><span class="line">    name = <span class="string">'book1'</span>     </span><br><span class="line">    custom_settings = &#123;     <span class="string">'ITEM_PIPELINES'</span>:&#123;<span class="string">'pipelineClass1'</span>: <span class="number">300</span>,<span class="string">'pipelineClass2'</span>: <span class="number">400</span>&#125;,                   &#125;</span><br></pre></td></tr></table></figure>

<p>这样可以解决多个Spider1时候指定ITEM_PIPELINES的问题，可以为每一个Spider指定数据处理的方式</p>
<p>需要注意的是最后一个ItemPipLine处理完成后，会根据命令行来进行处理后输出到哪里</p>
<p>scrapy crawl books -o books.csv</p>
<p>以上这段命令行中的-o books.csv是写入的文件，就是在最后一个ItemPipeline最后return的数据</p>
<p><strong>四、数据导出</strong></p>
<p>scrapy默认导出数据支持5种方式</p>
<p>JSON   JsonItemExporter</p>
<p>JSON lines   JsonLinesItemExporter</p>
<p>CSV  CsvItemExporter</p>
<p>XML  XmlItemExporter</p>
<p>Pickle  PickleItemExporter</p>
<p>Marshal MarsshallItemExporter</p>
<p>前4种是极为常用的文本数据格式，后面2种是Python特有的，scrapy本身没有准备Excel格式数据导出</p>
<p>如何导出？</p>
<p>方式一   命令行参数</p>
<p>-o -t参数指定导出文件路径和导出格式，通常t可以由o进行推测完成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl books -o books.csv</span><br></pre></td></tr></table></figure>

<p>scrapy crawl 是固定的</p>
<p>books是spider中的name</p>
<p>-o是输出的路径</p>
<p>books.csv 没有指定其他路径，就是在当前路径下，没有使用o,但是会根据提供的路径，推测出是csv</p>
<p>以下是指定明确的输出格式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl books -t json -o books.data</span><br></pre></td></tr></table></figure>

<p>这种数据导出，是依赖什么来进行完成的？</p>
<p>在配置字典FEED_EXPORTERS中搜索Exporter，FEED_EXPORTERS的内容中搜索Exporter，FEED_EXPORTERS的内容由以下二个字典的内容合并而成</p>
<p>默认配置文件中的FEED_EXPORTERS_BASE</p>
<p>用户配置文件中的FEED_EXPORTERS</p>
<p>前者包含内部支持的数据格式，后者包含用户自定义的导出数据格式，以下是Scrapy源码中定义的FEED_EXPORTERS_BASE，它位于scrapy.settings.default_settings模块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FEED_EXPORTERS_BASE=&#123;<span class="string">'json'</span>:<span class="string">'scrapy.exporters.JsonItemExporter'</span>,<span class="string">'jsonlines'</span>:<span class="string">'scrapy.exporters.JsonLinesItemExporter'</span>,<span class="string">'jl'</span>:<span class="string">'scrapy.exporters.JsonLinesItemExporter'</span>,<span class="string">'csv'</span>:<span class="string">'scrapy.exporters.CsvItemExporter'</span>,<span class="string">'xml'</span>:<span class="string">'scrapy.exporters.XmlItemExporter'</span>,<span class="string">'marshal'</span>:<span class="string">'scrapy.exporters.MarshalItemExporter'</span>,<span class="string">'pickle'</span>:<span class="string">'scrapy.exporters.PickleItemExporter'</span>,&#125;</span><br></pre></td></tr></table></figure>

<p>在这里严重不建议修改源码，因为程序最终是要配置在服务器上面的，服务器上面的环境修改源码，可就没那么简单了</p>
<p>用户添加新的导出格式，通常是在配置文件setting.py中定义FEED_EXPORTERS，比如导出Excel</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FEED_EXPORTERS=&#123;<span class="string">'excel'</span>:<span class="string">'my_project.my_exporters.ExcelItemExporter'</span>&#125;</span><br></pre></td></tr></table></figure>

<p>指定导出文件路径，支持%(name)s和%(time)s这2个特殊变量</p>
<p>%(name)s 会被替换为Spider的名字</p>
<p>%(time)s 会被替换为文件创建时间</p>
<p>假设一个项目爬取的有书籍、游戏信息、新闻3个spider</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl books  -o <span class="string">'/export_data/%(name)s/%(time)s.csv'</span></span><br><span class="line">scrapy crawl games  -o <span class="string">'/export_data/%(name)s/%(time)s.csv'</span></span><br><span class="line">scrapy crawl news  -o <span class="string">'/export_data/%(name)s/%(time)s.csv'</span></span><br></pre></td></tr></table></figure>

<p>以上是爬取的内容，根据书名存放在export_data文件夹下的对应书名目录下，每个目录下根据时间进行保存</p>
<p>方式二 配置文件方式</p>
<p>在setting.py中设置以下参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FEED_URI=<span class="string">'export_data/%(name)s.data'</span>            导出数据的位置</span><br><span class="line">FEED_FORMAT=<span class="string">'csv'</span>                               导出数据的格式</span><br><span class="line">FEED_EXPORT_ENCODING=<span class="string">'gbk'</span>                      导出数据的编码</span><br><span class="line">FEED_EXPORT_FIELDS=[<span class="string">'name'</span>,<span class="string">'author'</span>,<span class="string">'price'</span>]    导出数据的字段</span><br><span class="line">FEED_EXPORTERS=&#123;<span class="string">'excel'</span>:<span class="string">'my_project.my_exporters.ExcelItemExporter'</span>&#125;   新添加导出的格式</span><br></pre></td></tr></table></figure>

<p>如何实现一个自定义的导出的Excel类</p>
<p>1、继承BaseItemExporter</p>
<p>其中有3个方法</p>
<p>export_item(self,item) 负责导出爬取的每一项数据，参数item为一项爬取的数据，每一个子类必须实现该方法</p>
<p>start_exporting(self)   在导出开始时被调用，可在该方法执行某些初始化工作</p>
<p>finish_exporting(self) 在导出完成时候被调用，可在该方法中执行某些清理工作</p>
<p>以下实现一个导出Excel,注意这里使用的是xlwt，这个库最多只能在一个sheet中插入65535行数据，如果要插入更多数据，需要切换为openxl来进行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exporters <span class="keyword">import</span> BaseItemExporter</span><br><span class="line"> </span><br><span class="line">impoort xlwt</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExcelItemExporter</span><span class="params">(BaseItemExporter)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,file,**kwargs)</span>:</span></span><br><span class="line">       self._configure(kwargs)</span><br><span class="line">       self.file=file</span><br><span class="line">       self.wbook=xlwt.Workbook()</span><br><span class="line">       self.wsheet=self.wbook.add_sheet(<span class="string">'scrapy'</span>)</span><br><span class="line">       self.row=<span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">finish_exporting</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.wbook.save(self.file)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">export_item</span><span class="params">(self,item)</span>:</span></span><br><span class="line">        fields=self._get_serialized_fields(item)</span><br><span class="line">    <span class="keyword">for</span> col,v <span class="keyword">in</span> enumerate(x <span class="keyword">for</span> _,x <span class="keyword">in</span> fields):</span><br><span class="line">        self.wsheet.write(self.row,col,v)</span><br><span class="line"> </span><br><span class="line">    self.row +=<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>编写完成后再setting.py中添加这个类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FEED_EXPORTERS=&#123;<span class="string">'excel'</span>:<span class="string">'my_project.my_exporters.ExcelItemExporter'</span>&#125;</span><br></pre></td></tr></table></figure>

<p>之后终端命令行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl books -t excel -o books.xls</span><br></pre></td></tr></table></figure>

<p>这样就导出excel了，当然你可以封装一个Excel导出类，这样可以更加通用，在web框架下，爬虫框架下都可以使用</p>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls"
                data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
            <ul id="audio-list" style="display:none">
                
                
                <li title='0' data-url='/statics/chengdu.mp3'></li>
                
                    
            </ul>
            
            
            
    <div id='gitalk-container' class="comment link"
        data-ae='true'
        data-ci='ec894e2b66f752e8b7fb'
        data-cs='3ccc2e92bb350688fe2c2dc2930189b62622bfb1'
        data-r='blog-comments'
        data-o='TriDiamond'
        data-a='TriDiamond'
        data-d=''
    >留言</div>


            
            
        </div>
        <div class="sidebar">
            <div class="box animated fadeInRight">
                <div class="subbox">
                    <img src="https://res.cloudinary.com/tridiamond/image/upload/v1573019751/TriDiamond_logo_ui_xeublz.jpg" height=300 width=300></img>
                    <p>Juncon</p>
                    <span>Think like an artist, develop like an artisan</span>
                    <dl>
                        <dd><a href="https://github.com/TriDiamond" target="_blank"><span
                                    class=" iconfont icon-github"></span></a></dd>
                        <dd><a href="https://twitter.com/TriDiamond6" target="_blank"><span
                                    class=" iconfont icon-twitter"></span></a></dd>
                        <dd><a href="https://stackoverflow.com/users/7602324/tridiamond?tab=profile" target="_blank"><span
                                    class=" iconfont icon-stack-overflow"></span></a></dd>
                    </dl>
                </div>
                <ul>
                    <li><a href="/">27 <p>文章</p></a></li>
                    <li><a href="/categories">23 <p>分类</p></a></li>
                    <li><a href="/tags">23 <p>标签</p></a></li>
                </ul>
            </div>
            
            
            
            
        </div>
    </div>
</div>

    </div>
</div>
    <div id="back-to-top" class="animated fadeIn faster">
        <div class="flow"></div>
        <span class="percentage animated fadeIn faster">0%</span>
        <span class="iconfont icon-top02 animated fadeIn faster"></span>
    </div>
</body>
<footer>
    <p class="copyright" id="copyright">
        &copy; 2021
        <span class="gradient-text">
            Juncon
        </span>.
        Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
        Theme
        <span class="gradient-text">
            <a href="https://github.com/TriDiamond/hexo-theme-obsidian" title="Obsidian" target="_blank" rel="noopener">Obsidian</a>
        </span>
        <small><a href="https://github.com/TriDiamond/hexo-theme-obsidian/blob/master/CHANGELOG.md" title="v1.4.3" target="_blank" rel="noopener">v1.4.3</a></small>
    </p>
</footer>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script>
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX", "TeX"],
      linebreaks: {
        automatic: true
      },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"]
      ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      noUndefined: {
        attributes: {
          mathcolor: "red",
          mathbackground: "#FFEEEE",
          mathsize: "90%"
        }
      },
      Macros: {
        href: "{}"
      }
    },
    messageStyle: "none"
  });
</script>
<script>
  function initialMathJax() {
    MathJax.Hub.Queue(function () {
      var all = MathJax.Hub.getAllJax(),
        i;
      // console.log(all);
      for (i = 0; i < all.length; i += 1) {
        console.log(all[i].SourceElement().parentNode)
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  }

  function reprocessMathJax() {
    if (typeof MathJax !== 'undefined') {
      MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
    }
  }
</script>



    <link rel="stylesheet" href="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.css">
    <script src="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/obsidian.js"></script>
<script src="/js/jquery.truncate.js"></script>
<script src="/js/search.js"></script>
<script src="//cdn.bootcss.com/typed.js/2.0.10/typed.min.js"></script>
<script src="//cdn.bootcss.com/blueimp-md5/2.12.0/js/md5.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>

<script src="https://cdn.bootcss.com/codemirror/5.48.4/codemirror.min.js"></script>

    <script src="//cdn.bootcss.com/codemirror/5.48.4/mode/javascript/javascript.min.js"></script>

    <script src="//cdn.bootcss.com/codemirror/5.48.4/mode/css/css.min.js"></script>

    <script src="//cdn.bootcss.com/codemirror/5.48.4/mode/xml/xml.min.js"></script>

    <script src="//cdn.bootcss.com/codemirror/5.48.4/mode/htmlmixed/htmlmixed.min.js"></script>

    <script src="//cdn.bootcss.com/codemirror/5.48.4/mode/clike/clike.min.js"></script>

    <script src="//cdn.bootcss.com/codemirror/5.48.4/mode/php/php.min.js"></script>

    <script src="//cdn.bootcss.com/codemirror/5.48.4/mode/shell/shell.min.js"></script>

    <script src="//cdn.bootcss.com/codemirror/5.48.4/mode/python/python.min.js"></script>



    <script src="/js/busuanzi.min.js"></script>
    <script>
        $(document).ready(function () {
            if ($('span[id^="busuanzi_"]').length) {
                initialBusuanzi();
            }
        });
    </script>


<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>



    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="//www.googletagmanager.com/gtag/js?id=UA-149874671-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-149874671-1');
    </script>





<script>
    function initialTyped () {
        var typedTextEl = $('.typed-text');
        if (typedTextEl && typedTextEl.length > 0) {
            var typed = new Typed('.typed-text', {
                strings: ["Think like an artist, develop like an artisan", "艺术家思维去思考问题，工匠创造精神去开发"],
                typeSpeed: 90,
                loop: true,
                loopCount: Infinity,
                backSpeed: 20,
            });
        }
    }

    if ($('.article-header') && $('.article-header').length) {
        $(document).ready(function () {
            initialTyped();
        });
    }
</script>




</html>
